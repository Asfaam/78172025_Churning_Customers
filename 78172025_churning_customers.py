# -*- coding: utf-8 -*-
"""78172025_Churning_Customers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WvEZIEDADI7fdZuhEXH-_jPlEaJd0En-

### Mount colab onto google drive
"""

from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from math import sqrt
from sklearn.ensemble import RandomForestClassifier
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, roc_auc_score
import tensorflow as tf
from keras import layers
from tensorflow.keras.models import load_model
from tensorflow.keras.models import Model
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.layers import Input, Dense, Dropout
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,roc_curve, recall_score,
                                  classification_report, f1_score, precision_score)

# Reading the CSV File
Customer = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Intro to AI Folder/Assignment 3/CustomerChurn_dataset.csv')

# Display all columns
pd.set_option('display.max_columns', None)

Customer.head()

# Check the number of rows and columns in the Customer
Customer.shape

Customer.describe()

# Check for are Null Values
Customer.isnull().sum()

# check the data types of each column
Customer.info()

# From Customer dataset, 'TotalCharges' column has numericl values but we can see from the cell above that the data type of TotalCharges is object. We need to fix this issue.
Customer['TotalCharges'] = Customer['TotalCharges'].apply(lambda x: pd.to_numeric(x, errors='coerce')).dropna()

# check if TotalCharges has missing values
Customer['TotalCharges'].isnull().sum()

# From the cell above, TotalCharges 11 has missing values. Let's fill up the missing values
Customer['TotalCharges'] = Customer['TotalCharges'].fillna(Customer['TotalCharges'].median())

# confirm that the missing values in 'TotalCharges' has been imputed
Customer['TotalCharges'].isnull().sum()

# Looking at the format of the column names, there is an inconsistency. Lets correct them.
# rename customerID to CustomerID
Customer.rename(columns={'customerID':'CustomerID', }, inplace=True)

#  rename gender to Gender
Customer.rename(columns={'gender':'Gender', }, inplace=True)

# rename tenure to Tenure
Customer.rename(columns={'tenure':'Tenure', }, inplace=True)

# Some columns can be correct to have exactly two kinds of unique values so that they are either 'yes' or 'no'. Lets correct them
# correct 'No internet service' to 'No'
columns_having_no_internet_service = ['OnlineBackup','StreamingMovies','DeviceProtection',
                'TechSupport','OnlineSecurity','StreamingTV']
for i in columns_having_no_internet_service :
    Customer[i]  = Customer[i].replace({'No internet service' : 'No'})

# correct 'No phone service' to 'No'
Customer['MultipleLines'] = Customer['MultipleLines'].replace({'No phone service' : 'No'})

# Lets look at the dataset after all the changes above
Customer.head()

Customer.dtypes

"""### Exploratory Data Analysis (EDA)"""

# display the features or column names in Customer dataset
print("\nData Features:")
print(Customer.columns.tolist())

# show if there are any missing values
print("\nMissing values:",Customer.isnull().sum().values.sum())

# display the number of uniques values in eavh column
print("\n\nUnique values:")
print(Customer.nunique())

## number of customers who have churned
Customer["Churn"].value_counts()

sns.set(style="whitegrid")
plt.figure(figsize=(8, 6))

# Plotting a proportional bar graph for the 'Churn' column
churn_proportions = Customer['Churn'].value_counts(normalize=True)
sns.barplot(x=churn_proportions.index, y=churn_proportions.values, palette="viridis")

plt.title('Proportion of Customer Churn')
plt.xlabel('Churn')
plt.ylabel('Proportion')

# Display the plot
plt.show()

sns.set(style="whitegrid")
plt.figure(figsize=(8, 6))

# Count the number of males and females within each Churn category
gender_counts = Customer.groupby(['Churn', 'Gender']).size().reset_index(name='Count')

# Plotting a bar graph of Churn based on Gender
sns.barplot(x='Churn', y='Count', hue='Gender', data=gender_counts, palette="viridis", ci=None)

# Adding labels and title
plt.title('Count of Male and Female Customers based on Churn')
plt.xlabel('Churn')
plt.ylabel('Count')

# Display the plot
plt.show()

print("Summary Statistics:\n", Customer.describe())

# Visualize the distribution of the 'Churn' variable
sns.countplot(x='Churn', data=Customer, palette="viridis")
plt.title('Distribution of Churn')
plt.show()

# Explore categorical variables
categorical_columns = ['Gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',
                        'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',
                        'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']

for column in categorical_columns:
    plt.figure(figsize=(10, 6))
    sns.countplot(x=column, hue='Churn', data=Customer, palette="viridis")
    plt.title(f'Distribution of Churn based on {column}')
    plt.show()

# Explore numerical variables
numerical_columns = ['Tenure', 'MonthlyCharges', 'TotalCharges']

for column in numerical_columns:
    plt.figure(figsize=(10, 6))
    sns.histplot(data=Customer, x=column, hue='Churn', bins=30, kde=True, palette="viridis")
    plt.title(f'Distribution of {column} based on Churn')
    plt.show()

# Explore the correlation matrix
correlation_matrix = Customer.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

"""*The correlation matrix shows the visual representation of the numerical variables. It uses colour intensity to represent the strength and direction of correlations. Positive correlations are shown in warmer colors, negative correlations in cooler colors, and no correlation in shades of white.*

### Data Pre-processing
"""

# Let's drop 'CustomerID'; it is not relevant for customer churn prediction
selected_features = Customer.drop(['CustomerID'], axis = 1)

selected_features.head()

selected_features.shape

# Let's retrieve categorical features the dataset; selected_features
categorical_columns = selected_features.select_dtypes(include=['object']).columns

# Put the categorical features into a list
categorical_columns = categorical_columns.tolist()
categorical_columns

## Use Label encoding to convert all categorical columns to numeric
label_encoder = LabelEncoder()
for column in categorical_columns:
    selected_features[column] = label_encoder.fit_transform(selected_features[column])

selected_features.head()

"""### Feature Selection Using Random Forest classifier"""

X = selected_features.drop(['Churn'], axis = 1)
y = selected_features['Churn']

X.shape

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Random Forest classifier
rfc = RandomForestClassifier()

# Fit the classifier
rfc.fit(X, y)

# Get feature importances
feature_importances = rfc.feature_importances_

# Create a DataFrame to store feature names and their importances
df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

# Sort the DataFrame by importance in descending order
df = df.sort_values(by='Importance', ascending=False)

# Plot feature importances
top_features = 15  # Change this value to plot a different number of top features
plt.figure(figsize=(12, 6))
plt.barh(df['Feature'][:top_features], df['Importance'][:top_features])
plt.xlabel('Degree of Importance')
plt.title('Feature Importance')
plt.show()
relevant_features=df['Feature'][:top_features].values

# Display the list of important features
print("\n\nRelevant features:")
print(relevant_features)

"""### Training, Oversampling and Model Creation"""

X = selected_features[relevant_features]
y = selected_features['Churn']

X.shape

X.head()

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# scale the X_trin and X_test
standard_scaler = StandardScaler()
X_train = standard_scaler.fit_transform(X_train)
X_test = standard_scaler.fit_transform(X_test)

X_train

# The dataset is imbalanced. Let's oversample the minority class until the number of data points are equal to that of the majority class.
oversample = SMOTE(k_neighbors=5)
X_smote, y_smote = oversample.fit_resample(X_train, y_train)
X_train, y_train = X_smote, y_smote

y_train.value_counts()

# Define the architecture of the neural network using the Functional API

# Input layer
input_layer = Input(shape=(X_train.shape[1],))

# Dense layers
dense_layer_1 = Dense(64, activation='relu')(input_layer)
dense_layer_2 = Dense(32, activation='relu')(dense_layer_1)

# Output layer
output_layer = Dense(1, activation='sigmoid')(dense_layer_2)

# Define the model
model = Model(inputs=input_layer, outputs=output_layer, name="model")

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=32,
    validation_data=(X_test, y_test),
    verbose=0
)

## Display the model summary
model.summary()

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')


# Evaluate the model on the test set
y_pred = (model.predict(X_test) > 0.5).astype(int)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred)

print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'AUC Score:Â {roc_auc:.4f}')

## Evaluate the model's accuracy and calculate the AUC value.
y_pred = model.predict(X_test)
predictions = [np.round(value) for value in y_pred]

## Evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

## Calculate the AUC
fpr, tpr, thresholds = roc_curve(y_test, predictions)
roc_auc = auc(fpr, tpr)

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)
plt.legend(loc='lower right')
plt.plot([0,1],[0,1],'r--')
plt.xlim([-0.001, 1])
plt.ylim([0, 1.001])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show();

## Calculating the confidence factor
cofidence_factor = 2.58 * sqrt( (accuracy * (1 - accuracy)) / y_test.shape[0])
cofidence_factor

from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score, accuracy_score
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

# Function to create the Keras model
def create_model(units=64):
    input_layer = Input(shape=(X_train.shape[1],))
    dense_layer_1 = Dense(units, activation='relu')(input_layer)
    dense_layer_2 = Dense(32, activation='relu')(dense_layer_1)
    output_layer = Dense(1, activation='sigmoid')(dense_layer_2)

    model = Model(inputs=input_layer, outputs=output_layer)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    return model

# Create a KerasClassifier
keras_model = KerasClassifier(build_fn=create_model, epochs=5, batch_size=32, verbose=True)

# Define a smaller hyperparameter space for grid search
param_grid = {
    'batch_size': [32],
    'optimizer': ['adam'],
}

# Use GridSearchCV for hyperparameter tuning
grid_search = GridSearchCV(estimator=keras_model, param_grid=param_grid, scoring=['accuracy', 'roc_auc'], refit='roc_auc', cv=3, verbose=True)
grid_result = grid_search.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=True)

# Print the best parameters and corresponding accuracy
print("Accuracy is : %f using best parameters: %s" % (grid_result.best_score_, grid_result.best_params_))

# Get the best parameters
best_params = grid_result.best_params_
print("Best Parameters:", best_params)

# Get the best model
best_model = grid_result.best_estimator_
best_model_main = grid_result.best_estimator_.model

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
test_auc = roc_auc_score(y_test, y_pred)
test_accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))

print(f'Test AUC: {test_auc}, Test Accuracy: {test_accuracy}')

# Evaluate the best model on the test set
test_loss = best_model.score(X_test, y_test)

# Using best_model.predict_proba for obtaining probability estimates
y_pred_proba = best_model.predict_proba(X_test)[:, 1]
test_auc = roc_auc_score(y_test, y_pred_proba)

print(f'Test Loss: {test_loss}, Test AUC: {test_auc}, Test Accuracy: {test_accuracy}')

## Save the model
model = model.save('churn_model.h5')

## load the saved model to use for prediction
model = load_model('churn_model.h5')

# Evaluate the saved model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')

## Evaluate the saved model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

## Calculate accuracy and AUC score
accuracy = accuracy_score(y_test, y_pred_binary)
auc_score = roc_auc_score(y_test, y_pred)

print(f"\nAccuracy: {accuracy}")
print(f"\nAUC Score: {auc_score}")